service can be accessed only with in pod

pods will have unique ip address given by 

network namespace can be found under var/run/netns

CRI plugin creates a network names0pace 

when we not sepcify any namespace its used default namespace

within namespace object name should be unique 

we can use same object name for differnet namespaces

we have to carefully give selectors and labels for the specific pod to access or else we get error 

to enter inside container from pod we use --> kubectl exec -it podname -n namespacename-ns -- sh
in  the above if we have more continers in the pod it will exec by index value 0th index first

if we have more contianers in the pod we use contianer name -->kubectl exec -it podname -c contianername -n namespacename-ns -- sh

we communicate b/w pods within node by using localnetwork or pod ip 

service will act as a loadbalancer and service discovery 
 *cluster port we can access within cluster only 
 *nodeport we can access from outside cluster webpage 30000 to 32767 node port range

if we have 2 pods first pod will be executed if we execute pod 

if we want to execute specific container in a pod we have to give container name 
eg - kubectl exec -it podname -c containername bash 

curl -v servicename/containername --> communicates with a web or application serverby specifying a relevant URL and the data that need to be sent or received 

imp:
if 2 pods are in same namespace we communicate by using fqdn (FULLY QULIFIED DOMAIN NAME)
eg: curl -v servicename.namespacename.svc.cluster.local/contianerrname 
curl -vL mavenwebappsvc.test-ns.svc.cluster.local/mavenwebapplication 

Multicontainer pod.yml
we have to give different port numbers so we can use multicontainers
ports:
  - port: 8080
  - targetport: 8080
    name: tomcat
  - port: 80
  - targetport: 80
    name: nginix

if we have different namespace and we should access pods of different namespaces 

NAMESPACE
---------


PODLIFECYCLE
-----------
https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/

Pods follow a defined lifecycle, starting in the Pending phase, moving through Running if at least one of its primary containers starts OK, and then through either the Succeeded or Failed phases depending on whether any container in the Pod terminated in failure.

Whilst a Pod is running, the kubelet is able to restart containers to handle some kind of faults. Within a Pod, Kubernetes tracks different container states and determines what action to take to make the Pod healthy again

CONTROLL PROBES
---------------
Types of probe
The kubelet can optionally perform and react to three kinds of probes on running containers:

livenessProbe
Indicates whether the container is running. If the liveness probe fails, the kubelet kills the container, and the container is subjected to its restart policy. If a container does not provide a liveness probe, the default state is Success.

readinessProbe
Indicates whether the container is ready to respond to requests. If the readiness probe fails, the endpoints controller removes the Pod's IP address from the endpoints of all Services that match the Pod. The default state of readiness before the initial delay is Failure. If a container does not provide a readiness probe, the default state is Success.

startupProbe
Indicates whether the application within the container is started. All other probes are disabled if a startup probe is provided, until it succeeds. If the startup probe fails, the kubelet kills the container, and the container is subjected to its restart policy. If a container does not provide a startup probe, the default state is Success.

HPA
----
https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/

A HorizontalPodAutoscaler (HPA for short) automatically updates a workload resource (such as a Deployment or StatefulSet), with the aim of automatically scaling the workload to match demand.

Horizontal scaling means that the response to increased load is to deploy more Pods. This is different from vertical scaling, which for Kubernetes would mean assigning more resources (for example: memory or CPU)
to the Pods that are already running for the workload.

If the load decreases, and the number of Pods is above the configured minimum, the HorizontalPodAutoscaler instructs the workload resource (the Deployment, StatefulSet, or other similar resource) to scale back down.

he HPA controller will increase and decrease the number of replicas (by updating the Deployment) to maintain an average CPU utilization across all Pods of 50%. The Deployment then updates the ReplicaSet 
- this is part of how all Deployments work in Kubernetes - and then the ReplicaSet either adds or removes Pods based on the change to its .spec.

kubernetes we will create normally deplyment and attach HPA  to the deplyment we will use HPA scaletargetref (kind , name) to the deployment section same kind and name should match then only HPA will 
work as expected
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: php-apache
  minReplicas: 1
  maxReplicas: 10







